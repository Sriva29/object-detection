{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ipynb shows the use of two pre-trained models for object detection\n",
    "by Srivatsan Rangarajan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_cv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualization\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_cv'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_cv\n",
    "import numpy as np\n",
    "from keras_cv import visualization\n",
    "from keras_cv.layers import MultiClassNonMaxSuppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Download a street image\n",
    "street_image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Street_view_in_Philadelphia.jpg/800px-Street_view_in_Philadelphia.jpg\"\n",
    "street_image_path = tf.keras.utils.get_file(\"street_image.jpg\", origin=street_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and preprocess the image\n",
    "image = keras.utils.load_img(street_image_path)\n",
    "image = np.array(image)\n",
    "batched_image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a resizing layer to standardize the input size (640x640) with padding to preserve aspect ratio\n",
    "inference_resizing = keras_cv.layers.Resizing(\n",
    "    640, 640, pad_to_aspect_ratio=True, bounding_box_format=\"xywh\"\n",
    ")\n",
    "resized_image = inference_resizing(image)\n",
    "batched_resized_image = np.expand_dims(resized_image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load pretrained model 1: Faster R-CNN (COCO preset)\n",
    "fasterrcnn_model = keras_cv.models.FasterRCNN.from_preset(\n",
    "    \"fasterrcnn_resnet50_v1_coco\", bounding_box_format=\"xywh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load pretrained model 2: YOLO (COCO preset)\n",
    "# (Note: Ensure your keras_cv version supports the YOLO model and the chosen preset.)\n",
    "yolo_model = keras_cv.models.YOLO.from_preset(\n",
    "    \"yolo_v8_coco\", bounding_box_format=\"xywh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define a COCO class mapping (partial list for demonstration)\n",
    "coco_class_ids = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\",\n",
    "    \"traffic light\", \"fire hydrant\"\n",
    "]\n",
    "coco_class_mapping = dict(zip(range(len(coco_class_ids)), coco_class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Run inference using Faster R-CNN\n",
    "y_pred_frcnn = fasterrcnn_model.predict(batched_resized_image)\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    batched_resized_image,\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    y_pred=y_pred_frcnn,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=coco_class_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Run inference using YOLO\n",
    "y_pred_yolo = yolo_model.predict(batched_resized_image)\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    batched_resized_image,\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    y_pred=y_pred_yolo,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=coco_class_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Adjust detection thresholds via Non-Max Suppression (NMS)\n",
    "# For Faster R-CNN: Tighter thresholds for more selective detections\n",
    "nms_frcnn = MultiClassNonMaxSuppression(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    from_logits=True,\n",
    "    iou_threshold=0.2,          # Lower IoU threshold\n",
    "    confidence_threshold=0.7,     # Higher confidence threshold\n",
    ")\n",
    "fasterrcnn_model.prediction_decoder = nms_frcnn\n",
    "y_pred_frcnn_adjusted = fasterrcnn_model.predict(batched_resized_image)\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    batched_resized_image,\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    y_pred=y_pred_frcnn_adjusted,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=coco_class_mapping,\n",
    ")\n",
    "\n",
    "# For YOLO: Similar threshold adjustment\n",
    "nms_yolo = MultiClassNonMaxSuppression(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    from_logits=True,\n",
    "    iou_threshold=0.2,\n",
    "    confidence_threshold=0.7,\n",
    ")\n",
    "yolo_model.prediction_decoder = nms_yolo\n",
    "y_pred_yolo_adjusted = yolo_model.predict(batched_resized_image)\n",
    "visualization.plot_bounding_box_gallery(\n",
    "    batched_resized_image,\n",
    "    value_range=(0, 255),\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    y_pred=y_pred_yolo_adjusted,\n",
    "    scale=5,\n",
    "    font_scale=0.7,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    class_mapping=coco_class_mapping,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emoart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
